{
 "cells": [
  {
   "cell_type": "code",
   "id": "a89f7c3b-b8a4-4278-b95d-d761fbc43dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:15:06.390842Z",
     "start_time": "2024-12-16T12:15:02.966859Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('/diffusers/src')\n",
    "\n",
    "from diffusers.models.attention_processor import (\n",
    "    Attention,\n",
    "    AttnProcessor,\n",
    "    AttentionProcessor,\n",
    "    FluxAttnProcessor2_0,\n",
    "    FluxAttnProcessor2_0_NPU,\n",
    "    FusedFluxAttnProcessor2_0,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e729830c-2104-48e6-a0d2-211ece4895aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:15:09.970457Z",
     "start_time": "2024-12-16T12:15:06.568341Z"
    }
   },
   "source": [
    "import torch\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "# 加载基础模型管道\n",
    "flux_pipe = AutoPipelineForText2Image.from_pretrained(\"/mnt/d/studying-code/modelscope/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
    "flux_pipe.enable_sequential_cpu_offload()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b64b71195705450d8cd0bddfaa68a56f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87cd2b3783de4ed9b9a9cd7a47d068e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "74b03c2a-197c-4293-a7a5-f0b6b24fb78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:15:13.271181Z",
     "start_time": "2024-12-16T12:15:13.254615Z"
    }
   },
   "source": [
    "from typing import Optional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EmbeddingInsertAttnProcessor(AttnProcessor):\n",
    "    def __init__(self):\n",
    "        if not hasattr(F, \"scaled_dot_product_attention\"):\n",
    "            raise ImportError(\"FluxAttnProcessor2_0 requires PyTorch 2.0, to use it, please upgrade PyTorch to 2.0.\")\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        attn: Attention,\n",
    "        hidden_states: torch.FloatTensor,\n",
    "        encoder_hidden_states: torch.FloatTensor = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        image_rotary_emb: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        batch_size, _, _ = hidden_states.shape if encoder_hidden_states is None else encoder_hidden_states.shape\n",
    "\n",
    "        # `sample` projections.\n",
    "        query = attn.to_q(hidden_states)\n",
    "        key = attn.to_k(hidden_states)\n",
    "        value = attn.to_v(hidden_states)\n",
    "\n",
    "        inner_dim = key.shape[-1]\n",
    "        head_dim = inner_dim // attn.heads\n",
    "\n",
    "        query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
    "        key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
    "        value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
    "\n",
    "        if attn.norm_q is not None:\n",
    "            query = attn.norm_q(query)\n",
    "        if attn.norm_k is not None:\n",
    "            key = attn.norm_k(key)\n",
    "\n",
    "        # the attention in FluxSingleTransformerBlock does not use `encoder_hidden_states`\n",
    "        if encoder_hidden_states is not None:\n",
    "            # `context` projections.\n",
    "            encoder_hidden_states_query_proj = attn.add_q_proj(encoder_hidden_states)\n",
    "            encoder_hidden_states_key_proj = attn.add_k_proj(encoder_hidden_states)\n",
    "            encoder_hidden_states_value_proj = attn.add_v_proj(encoder_hidden_states)\n",
    "\n",
    "            encoder_hidden_states_query_proj = encoder_hidden_states_query_proj.view(\n",
    "                batch_size, -1, attn.heads, head_dim\n",
    "            ).transpose(1, 2)\n",
    "            encoder_hidden_states_key_proj = encoder_hidden_states_key_proj.view(\n",
    "                batch_size, -1, attn.heads, head_dim\n",
    "            ).transpose(1, 2)\n",
    "            encoder_hidden_states_value_proj = encoder_hidden_states_value_proj.view(\n",
    "                batch_size, -1, attn.heads, head_dim\n",
    "            ).transpose(1, 2)\n",
    "\n",
    "            if attn.norm_added_q is not None:\n",
    "                encoder_hidden_states_query_proj = attn.norm_added_q(encoder_hidden_states_query_proj)\n",
    "            if attn.norm_added_k is not None:\n",
    "                encoder_hidden_states_key_proj = attn.norm_added_k(encoder_hidden_states_key_proj)\n",
    "\n",
    "            # attention\n",
    "            query = torch.cat([encoder_hidden_states_query_proj, query], dim=2)\n",
    "            key = torch.cat([encoder_hidden_states_key_proj, key], dim=2)\n",
    "            value = torch.cat([encoder_hidden_states_value_proj, value], dim=2)\n",
    "\n",
    "        if image_rotary_emb is not None:\n",
    "            from diffusers.models.embeddings import apply_rotary_emb\n",
    "\n",
    "            query = apply_rotary_emb(query, image_rotary_emb)\n",
    "            key = apply_rotary_emb(key, image_rotary_emb)\n",
    "\n",
    "        hidden_states = F.scaled_dot_product_attention(\n",
    "            query, key, value, attn_mask=attention_mask, dropout_p=0.0, is_causal=False\n",
    "        )\n",
    "        hidden_states = hidden_states.transpose(1, 2).reshape(batch_size, -1, attn.heads * head_dim)\n",
    "        hidden_states = hidden_states.to(query.dtype)\n",
    "\n",
    "        if encoder_hidden_states is not None:\n",
    "            encoder_hidden_states, hidden_states = (\n",
    "                hidden_states[:, : encoder_hidden_states.shape[1]],\n",
    "                hidden_states[:, encoder_hidden_states.shape[1] :],\n",
    "            )\n",
    "\n",
    "            # linear proj\n",
    "            hidden_states = attn.to_out[0](hidden_states)\n",
    "            # dropout\n",
    "            hidden_states = attn.to_out[1](hidden_states)\n",
    "\n",
    "            encoder_hidden_states = attn.to_add_out(encoder_hidden_states)\n",
    "\n",
    "            return hidden_states, encoder_hidden_states\n",
    "        else:\n",
    "            return hidden_states"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:15:18.277688Z",
     "start_time": "2024-12-16T12:15:18.248504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_processor_dict = {}\n",
    "change_block = 9\n",
    "for index, k in enumerate(flux_pipe.transformer.attn_processors):\n",
    "    # 0-18 is FluxTransformerBlock, 19-56 is FluxSingleTransformerBlock\n",
    "    if index == change_block:\n",
    "        attn_processor_dict[k] = EmbeddingInsertAttnProcessor()\n",
    "    else:\n",
    "        attn_processor_dict[k] = FluxAttnProcessor2_0()\n",
    "\n",
    "flux_pipe.transformer.set_attn_processor(attn_processor_dict)"
   ],
   "id": "b6c60e07290875ba",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:16:03.033493Z",
     "start_time": "2024-12-16T12:15:23.240095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt1 = [\"A photo of a tiger\"]\n",
    "prompt2 = [\"A photo of a bunny\"]\n",
    "\n",
    "res = flux_pipe(\n",
    "    prompt1,\n",
    "    guidance_scale=0.0,\n",
    "    num_inference_steps=4,\n",
    "    max_sequence_length=256,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0),\n",
    ")"
   ],
   "id": "8d38ac9cd8016ed3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b463f08c14374353871322e8d9a1a860"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "1024\n",
      "256\n",
      "1024\n",
      "256\n",
      "1024\n",
      "256\n",
      "1024\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:16:03.040114Z",
     "start_time": "2024-12-16T12:16:03.036409Z"
    }
   },
   "cell_type": "code",
   "source": "image = res.images[0]",
   "id": "6ab6b699a3d30198",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:17:02.222412Z",
     "start_time": "2024-12-16T12:17:02.084861Z"
    }
   },
   "cell_type": "code",
   "source": "image.show()",
   "id": "c06853e844416cec",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee683014489eb4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
